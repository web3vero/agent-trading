"""
ğŸŒ™ Moon Dev's Groq Model Implementation
Built with love by Moon Dev ğŸš€
"""

from groq import Groq
from termcolor import cprint
from .base_model import BaseModel, ModelResponse
import time

class GroqModel(BaseModel):
    """Implementation for Groq's models"""
    
    AVAILABLE_MODELS = {
        # Production Models
        "mixtral-8x7b-32768": {
            "description": "Mixtral 8x7B - Production - 32k context",
            "input_price": "$0.27/1M tokens",
            "output_price": "$0.27/1M tokens"
        },
        "gemma2-9b-it": {
            "description": "Google Gemma 2 9B - Production - 8k context",
            "input_price": "$0.10/1M tokens",
            "output_price": "$0.10/1M tokens"
        },
        "llama-3.3-70b-versatile": {
            "description": "Llama 3.3 70B Versatile - Production - 128k context",
            "input_price": "$0.70/1M tokens",
            "output_price": "$0.90/1M tokens"
        },
        "llama-3.1-8b-instant": {
            "description": "Llama 3.1 8B Instant - Production - 128k context",
            "input_price": "$0.10/1M tokens",
            "output_price": "$0.10/1M tokens"
        },
        "llama-guard-3-8b": {
            "description": "Llama Guard 3 8B - Production - 8k context",
            "input_price": "$0.20/1M tokens",
            "output_price": "$0.20/1M tokens"
        },
        "llama3-70b-8192": {
            "description": "Llama 3 70B - Production - 8k context",
            "input_price": "$0.70/1M tokens",
            "output_price": "$0.90/1M tokens"
        },
        "llama3-8b-8192": {
            "description": "Llama 3 8B - Production - 8k context",
            "input_price": "$0.10/1M tokens",
            "output_price": "$0.10/1M tokens"
        },
        # Preview Models
        "deepseek-r1-distill-llama-70b": {
            "description": "DeepSeek R1 Distill Llama 70B - Preview - 128k context",
            "input_price": "$0.70/1M tokens",
            "output_price": "$0.90/1M tokens"
        },
        "llama-3.3-70b-specdec": {
            "description": "Llama 3.3 70B SpecDec - Preview - 8k context",
            "input_price": "$0.70/1M tokens",
            "output_price": "$0.90/1M tokens"
        },
        "llama-3.2-1b-preview": {
            "description": "Llama 3.2 1B - Preview - 128k context",
            "input_price": "$0.05/1M tokens",
            "output_price": "$0.05/1M tokens"
        },
        "llama-3.2-3b-preview": {
            "description": "Llama 3.2 3B - Preview - 128k context",
            "input_price": "$0.07/1M tokens",
            "output_price": "$0.07/1M tokens"
        }
    }
    
    def __init__(self, api_key: str, model_name: str = "mixtral-8x7b-32768", **kwargs):
        try:
            cprint(f"\nğŸŒ™ Moon Dev's Groq Model Initialization", "cyan")
            
            # Validate API key
            if not api_key or len(api_key.strip()) == 0:
                raise ValueError("API key is empty or None")
            
            cprint(f"ğŸ”‘ API Key validation:", "cyan")
            cprint(f"  â”œâ”€ Length: {len(api_key)} chars", "cyan")
            cprint(f"  â”œâ”€ Contains whitespace: {'yes' if any(c.isspace() for c in api_key) else 'no'}", "cyan")
            cprint(f"  â””â”€ Starts with 'gsk_': {'yes' if api_key.startswith('gsk_') else 'no'}", "cyan")
            
            # Validate model name
            cprint(f"\nğŸ“ Model validation:", "cyan")
            cprint(f"  â”œâ”€ Requested: {model_name}", "cyan")
            if model_name not in self.AVAILABLE_MODELS:
                cprint(f"  â””â”€ âŒ Invalid model name", "red")
                cprint("\nAvailable models:", "yellow")
                for available_model, info in self.AVAILABLE_MODELS.items():
                    cprint(f"  â”œâ”€ {available_model}", "yellow")
                    cprint(f"  â”‚  â””â”€ {info['description']}", "yellow")
                raise ValueError(f"Invalid model name: {model_name}")
            cprint(f"  â””â”€ âœ… Model name valid", "green")
            
            self.model_name = model_name
            
            # Call parent class initialization
            cprint(f"\nğŸ“¡ Parent class initialization...", "cyan")
            super().__init__(api_key, **kwargs)
            cprint(f"âœ… Parent class initialized", "green")
            
        except Exception as e:
            cprint(f"\nâŒ Error in Groq model initialization", "red")
            cprint(f"  â”œâ”€ Error type: {type(e).__name__}", "red")
            cprint(f"  â”œâ”€ Error message: {str(e)}", "red")
            if "api_key" in str(e).lower():
                cprint(f"  â”œâ”€ ğŸ”‘ This appears to be an API key issue", "red")
                cprint(f"  â””â”€ Please check your GROQ_API_KEY in .env", "red")
            elif "model" in str(e).lower():
                cprint(f"  â”œâ”€ ğŸ¤– This appears to be a model name issue", "red")
                cprint(f"  â””â”€ Available models: {list(self.AVAILABLE_MODELS.keys())}", "red")
            raise
    
    def initialize_client(self, **kwargs) -> None:
        """Initialize the Groq client"""
        try:
            cprint(f"\nğŸ”Œ Initializing Groq client...", "cyan")
            cprint(f"  â”œâ”€ API Key length: {len(self.api_key)} chars", "cyan")
            cprint(f"  â”œâ”€ Model name: {self.model_name}", "cyan")
            
            cprint(f"\n  â”œâ”€ Creating Groq client...", "cyan")
            self.client = Groq(api_key=self.api_key)
            cprint(f"  â”œâ”€ âœ… Groq client created", "green")
            
            # Get list of available models first
            cprint(f"  â”œâ”€ Fetching available models from Groq API...", "cyan")
            available_models = self.client.models.list()
            api_models = [model.id for model in available_models.data]
            cprint(f"  â”œâ”€ Models available from API: {api_models}", "cyan")
            
            if self.model_name not in api_models:
                cprint(f"  â”œâ”€ âš ï¸ Requested model not found in API", "yellow")
                cprint(f"  â”œâ”€ Falling back to mixtral-8x7b-32768", "yellow")
                self.model_name = "mixtral-8x7b-32768"
            
            # Test the connection with a simple completion
            cprint(f"  â”œâ”€ Testing connection with model: {self.model_name}", "cyan")
            test_response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": "Hello"}],
                max_tokens=10
            )
            cprint(f"  â”œâ”€ âœ… Test response received", "green")
            cprint(f"  â”œâ”€ Response content: {test_response.choices[0].message.content}", "cyan")
            
            model_info = self.AVAILABLE_MODELS.get(self.model_name, {})
            cprint(f"  â”œâ”€ âœ¨ Groq model initialized: {self.model_name}", "green")
            cprint(f"  â”œâ”€ Model info: {model_info.get('description', '')}", "cyan")
            cprint(f"  â””â”€ Pricing: Input {model_info.get('input_price', '')} | Output {model_info.get('output_price', '')}", "yellow")
            
        except Exception as e:
            cprint(f"\nâŒ Failed to initialize Groq client", "red")
            cprint(f"  â”œâ”€ Error type: {type(e).__name__}", "red")
            cprint(f"  â”œâ”€ Error message: {str(e)}", "red")
            
            # Check for specific error types
            if "api_key" in str(e).lower():
                cprint(f"  â”œâ”€ ğŸ”‘ This appears to be an API key issue", "red")
                cprint(f"  â”œâ”€ Make sure your GROQ_API_KEY is correct", "red")
                cprint(f"  â””â”€ Key length: {len(self.api_key)} chars", "red")
            elif "model" in str(e).lower():
                cprint(f"  â”œâ”€ ğŸ¤– This appears to be a model name issue", "red")
                cprint(f"  â”œâ”€ Requested model: {self.model_name}", "red")
                cprint(f"  â””â”€ Available models: {list(self.AVAILABLE_MODELS.keys())}", "red")
            
            if hasattr(e, 'response'):
                cprint(f"  â”œâ”€ Response status: {e.response.status_code}", "red")
                cprint(f"  â””â”€ Response body: {e.response.text}", "red")
            
            if hasattr(e, '__traceback__'):
                import traceback
                cprint(f"\nğŸ“‹ Full traceback:", "red")
                cprint(traceback.format_exc(), "red")
            
            self.client = None
            raise
    
    def generate_response(self, system_prompt, user_content, temperature=0.7, max_tokens=None):
        """Generate response with no caching"""
        try:
            # Force unique request every time
            timestamp = int(time.time() * 1000)  # Millisecond precision
            
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"{user_content}_{timestamp}"}  # Make each request unique
                ],
                temperature=temperature,
                max_tokens=max_tokens if max_tokens else self.max_tokens,
                stream=False  # Disable streaming to prevent caching
            )
            
            return ModelResponse(
                content=response.choices[0].message.content,
                raw_response=response,
                model_name=self.model_name,
                usage=response.usage
            )
            
        except Exception as e:
            if "503" in str(e):
                raise e
            cprint(f"âŒ Groq error: {str(e)}", "red")
            return None
    
    def is_available(self) -> bool:
        """Check if Groq is available"""
        return self.client is not None
    
    @property
    def model_type(self) -> str:
        return "groq" 